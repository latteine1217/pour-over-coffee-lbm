"""
ä¼æ¥­ç´šè¨ˆç®—å¾Œç«¯åŸºé¡èˆ‡å·¥å» æ¨¡å¼
æä¾›çµ±ä¸€çš„è¨ˆç®—æ¥å£ï¼Œæ”¯æ´ä¸åŒå¹³å°çš„æœ€ä½³è¨ˆç®—ç­–ç•¥

æ ¸å¿ƒç‰¹æ€§ï¼š
- çµ±ä¸€å¾Œç«¯ä»‹é¢èˆ‡éŒ¯èª¤è™•ç†
- ä¼æ¥­ç´šå·¥å» æ¨¡å¼èˆ‡å¹³å°æª¢æ¸¬
- è‡ªå‹•é™ç´šèˆ‡æ•…éšœè½‰ç§»æ©Ÿåˆ¶
- å®Œæ•´çš„æ€§èƒ½ç›£æ§èˆ‡è¨ºæ–·
- æ™ºèƒ½å¾Œç«¯é¸æ“‡èˆ‡é…ç½®

é–‹ç™¼ï¼šopencode + GitHub Copilot
"""

import taichi as ti
import numpy as np
from abc import ABC, abstractmethod
from typing import Optional, Tuple, Dict, Any, List
import sys
import os
import platform
import subprocess
import logging
import time
from enum import Enum
import threading
from contextlib import contextmanager

sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(__file__)))))
import config.config


# ===== éŒ¯èª¤è™•ç†ç³»çµ± =====

class BackendError(Exception):
    """å¾Œç«¯éŒ¯èª¤åŸºé¡"""
    def __init__(self, message: str, backend_type: Optional[str] = None, error_code: Optional[str] = None):
        self.backend_type = backend_type or "unknown"
        self.error_code = error_code or "UNKNOWN_ERROR"
        super().__init__(message)


class PlatformDetectionError(BackendError):
    """å¹³å°æª¢æ¸¬éŒ¯èª¤"""
    pass


class BackendInitializationError(BackendError):
    """å¾Œç«¯åˆå§‹åŒ–éŒ¯èª¤"""
    pass


class ComputeExecutionError(BackendError):
    """è¨ˆç®—åŸ·è¡ŒéŒ¯èª¤"""
    pass


class MemoryAllocationError(BackendError):
    """è¨˜æ†¶é«”åˆ†é…éŒ¯èª¤"""
    pass


class PerformanceDegradationError(BackendError):
    """æ€§èƒ½é™ç´šéŒ¯èª¤"""
    pass


# ===== å¹³å°é¡å‹å®šç¾© =====

class PlatformType(Enum):
    """æ”¯æ´çš„å¹³å°é¡å‹"""
    APPLE_SILICON = "apple"
    NVIDIA_CUDA = "cuda" 
    CPU_REFERENCE = "cpu"
    UNKNOWN = "unknown"


class BackendPriority(Enum):
    """å¾Œç«¯å„ªå…ˆç´š"""
    CRITICAL = 1    # æ ¸å¿ƒåŠŸèƒ½ï¼Œå¿…é ˆæˆåŠŸ
    HIGH = 2        # é«˜æ€§èƒ½éœ€æ±‚
    MEDIUM = 3      # æ¨™æº–éœ€æ±‚
    LOW = 4         # å‚™ç”¨æ–¹æ¡ˆ


# ===== çµ±ä¸€æ—¥èªŒç³»çµ± =====

class BackendLogger:
    """çµ±ä¸€å¾Œç«¯æ—¥èªŒç®¡ç†"""
    
    def __init__(self):
        self.logger = logging.getLogger("compute_backends")
        if not self.logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
            self.logger.setLevel(logging.INFO)
    
    def info(self, message: str, backend_type: Optional[str] = None):
        prefix = f"[{backend_type}] " if backend_type else ""
        self.logger.info(f"{prefix}{message}")
    
    def warning(self, message: str, backend_type: Optional[str] = None):
        prefix = f"[{backend_type}] " if backend_type else ""
        self.logger.warning(f"{prefix}{message}")
    
    def error(self, message: str, backend_type: Optional[str] = None):
        prefix = f"[{backend_type}] " if backend_type else ""
        self.logger.error(f"{prefix}{message}")


# å…¨åŸŸæ—¥èªŒå¯¦ä¾‹
backend_logger = BackendLogger()


# ===== å¹³å°æª¢æ¸¬ç³»çµ± =====

class PlatformDetector:
    """
    æ™ºèƒ½å¹³å°æª¢æ¸¬ç³»çµ±
    
    åŠŸèƒ½ç‰¹æ€§ï¼š
    - å¤šå±¤æ¬¡ç¡¬é«”æª¢æ¸¬èˆ‡é©—è­‰
    - æ€§èƒ½åŸºæº–æ¸¬è©¦èˆ‡è©•åˆ†
    - è‡ªå‹•é™ç´šèˆ‡æ•…éšœè½‰ç§»
    - ç³»çµ±è³‡æºç›£æ§
    """
    
    def __init__(self):
        self.detected_platforms = []
        self.performance_scores = {}
        self.availability_cache = {}
        self.lock = threading.Lock()
        
    def detect_all_platforms(self) -> List[Dict[str, Any]]:
        """
        æª¢æ¸¬æ‰€æœ‰å¯ç”¨å¹³å°
        
        Returns:
            List[Dict]: å¹³å°ä¿¡æ¯åˆ—è¡¨ï¼ŒæŒ‰å„ªå…ˆç´šæ’åº
        """
        with self.lock:
            platforms = []
            
            # Apple Silicon æª¢æ¸¬
            apple_info = self._detect_apple_silicon()
            if apple_info:
                platforms.append(apple_info)
                
            # NVIDIA CUDA æª¢æ¸¬
            cuda_info = self._detect_nvidia_cuda()
            if cuda_info:
                platforms.append(cuda_info)
                
            # CPU åƒè€ƒå¯¦ç¾
            cpu_info = self._detect_cpu_platform()
            platforms.append(cpu_info)  # CPU ç¸½æ˜¯å¯ç”¨
            
            # æŒ‰æ€§èƒ½è©•åˆ†æ’åº
            platforms.sort(key=lambda x: x.get('performance_score', 0), reverse=True)
            
            self.detected_platforms = platforms
            return platforms
    
    def _detect_apple_silicon(self) -> Optional[Dict[str, Any]]:
        """æª¢æ¸¬ Apple Silicon å¹³å°"""
        try:
            # åŸºæœ¬å¹³å°æª¢æ¸¬
            if not (platform.processor() in ['arm', 'arm64'] and platform.system() == 'Darwin'):
                return None
                
            # æª¢æ¸¬ Metal æ”¯æ´
            try:
                ti.init(arch=ti.metal)
                metal_available = True
                ti.reset()
            except Exception:
                metal_available = False
                
            if not metal_available:
                backend_logger.warning("Apple Silicon æª¢æ¸¬åˆ°ï¼Œä½† Metal ä¸å¯ç”¨", "apple")
                return None
            
            # ç²å–ç³»çµ±ä¿¡æ¯
            try:
                import subprocess
                system_info = subprocess.check_output(['system_profiler', 'SPHardwareDataType'], 
                                                    text=True, timeout=5)
                chip_name = "Apple Silicon"
                for line in system_info.split('\n'):
                    if 'Chip:' in line:
                        chip_name = line.split(':')[1].strip()
                        break
            except Exception:
                chip_name = "Apple Silicon"
                
            return {
                'platform_type': PlatformType.APPLE_SILICON,
                'backend_name': 'apple',
                'display_name': f'ğŸ {chip_name} (Metal GPU)',
                'performance_score': 95,  # é«˜æ€§èƒ½è©•åˆ†
                'memory_type': 'unified',
                'compute_units': 'GPU',
                'chip_name': chip_name,
                'metal_available': True,
                'priority': BackendPriority.HIGH
            }
            
        except Exception as e:
            backend_logger.error(f"Apple Silicon æª¢æ¸¬å¤±æ•—: {e}", "apple")
            return None
    
    def _detect_nvidia_cuda(self) -> Optional[Dict[str, Any]]:
        """æª¢æ¸¬ NVIDIA CUDA å¹³å°"""
        try:
            # æª¢æ¸¬ nvidia-smi
            try:
                result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', 
                                       '--format=csv,noheader,nounits'], 
                                      capture_output=True, text=True, timeout=10)
                if result.returncode != 0:
                    return None
                    
                gpu_info = result.stdout.strip().split('\n')[0].split(', ')
                gpu_name = gpu_info[0]
                gpu_memory = int(gpu_info[1])
                
            except (subprocess.TimeoutExpired, FileNotFoundError, IndexError):
                return None
                
            # æª¢æ¸¬ CUDA æ”¯æ´
            try:
                ti.init(arch=ti.cuda)
                cuda_available = True
                ti.reset()
            except Exception:
                cuda_available = False
                
            if not cuda_available:
                backend_logger.warning("NVIDIA GPU æª¢æ¸¬åˆ°ï¼Œä½† CUDA ä¸å¯ç”¨", "cuda")
                return None
                
            # è¨ˆç®—æ€§èƒ½è©•åˆ† (åŸºæ–¼è¨˜æ†¶é«”å®¹é‡)
            performance_score = min(90, 60 + (gpu_memory // 1000) * 5)
            
            return {
                'platform_type': PlatformType.NVIDIA_CUDA,
                'backend_name': 'cuda',
                'display_name': f'ğŸš€ {gpu_name} (CUDA)',
                'performance_score': performance_score,
                'memory_type': 'dedicated',
                'compute_units': 'CUDA Cores',
                'gpu_name': gpu_name,
                'gpu_memory_mb': gpu_memory,
                'cuda_available': True,
                'priority': BackendPriority.HIGH
            }
            
        except Exception as e:
            backend_logger.error(f"NVIDIA CUDA æª¢æ¸¬å¤±æ•—: {e}", "cuda")
            return None
    
    def _detect_cpu_platform(self) -> Dict[str, Any]:
        """æª¢æ¸¬ CPU å¹³å° (ç¸½æ˜¯å¯ç”¨)"""
        try:
            try:
                import psutil
                cpu_count = psutil.cpu_count(logical=False)
                cpu_freq = psutil.cpu_freq()
                memory_gb = psutil.virtual_memory().total // (1024**3)
                
                # åŸºæ–¼ CPU æ ¸å¿ƒæ•¸å’Œé »ç‡è¨ˆç®—æ€§èƒ½è©•åˆ†
                base_score = 30
                core_score = min(20, cpu_count * 2) if cpu_count else 10
                freq_score = min(20, (cpu_freq.max / 1000 - 2) * 5) if cpu_freq and cpu_freq.max else 10
                memory_score = min(10, memory_gb // 4)
                
                performance_score = base_score + core_score + freq_score + memory_score
                
            except ImportError:
                performance_score = 40  # é»˜èªè©•åˆ†
                cpu_count = "Unknown"
                memory_gb = "Unknown"
                
        except Exception:
            performance_score = 40
            cpu_count = "Unknown"
            memory_gb = "Unknown"
            
        return {
            'platform_type': PlatformType.CPU_REFERENCE,
            'backend_name': 'cpu',
            'display_name': f'ğŸ–¥ï¸ CPU ({cpu_count} cores, {memory_gb}GB RAM)',
            'performance_score': performance_score,
            'memory_type': 'system',
            'compute_units': 'CPU Cores',
            'cpu_cores': cpu_count,
            'memory_gb': memory_gb,
            'priority': BackendPriority.MEDIUM
        }
    
    def get_optimal_platform(self) -> Dict[str, Any]:
        """ç²å–æœ€ä½³å¹³å°é…ç½®"""
        if not self.detected_platforms:
            self.detect_all_platforms()
            
        return self.detected_platforms[0] if self.detected_platforms else self._detect_cpu_platform()
    
    def validate_platform_availability(self, platform_name: str) -> bool:
        """é©—è­‰å¹³å°å¯ç”¨æ€§"""
        try:
            if platform_name == 'apple':
                ti.init(arch=ti.metal)
            elif platform_name == 'cuda':
                ti.init(arch=ti.cuda)
            elif platform_name == 'cpu':
                ti.init(arch=ti.cpu)
            else:
                return False
                
            ti.reset()
            return True
            
        except Exception as e:
            backend_logger.error(f"å¹³å° {platform_name} é©—è­‰å¤±æ•—: {e}")
            return False


# å…¨åŸŸå¹³å°æª¢æ¸¬å™¨
platform_detector = PlatformDetector()


# ===== çµ±ä¸€è¨ˆç®—å¾Œç«¯åŸºé¡ =====

class ComputeBackend(ABC):
    """
    ä¼æ¥­ç´šè¨ˆç®—å¾Œç«¯åŸºé¡
    
    å®šç¾©çµ±ä¸€çš„è¨ˆç®—æ¥å£ï¼Œæ”¯æ´ä¸åŒçš„è¨ˆç®—ç­–ç•¥ï¼š
    - Apple Silicon: Metal GPUæ·±åº¦å„ªåŒ–
    - NVIDIA CUDA: é«˜æ€§èƒ½ä¸¦è¡Œè¨ˆç®—
    - CPU Reference: è·¨å¹³å°åƒè€ƒå¯¦ç¾
    
    æ ¸å¿ƒç‰¹æ€§ï¼š
    - çµ±ä¸€ API ä»‹é¢
    - ä¼æ¥­ç´šéŒ¯èª¤è™•ç†
    - æ€§èƒ½ç›£æ§èˆ‡è¨ºæ–·
    - è³‡æºç®¡ç†èˆ‡æ¸…ç†
    """
    
    def __init__(self, backend_type: str = "base"):
        self.backend_type = backend_type
        self.performance_metrics = {}
        self.error_history = []
        self.is_initialized = False
        self.creation_time = time.time()
        self.last_error = None
        
        # æ€§èƒ½ç›£æ§
        self.execution_times = []
        self.memory_usage = []
        self.operation_count = 0
        
    @abstractmethod
    def execute_collision_streaming(self, memory_adapter, **kwargs) -> None:
        """
        åŸ·è¡Œcollision-streamingèåˆæ­¥é©Ÿ
        
        Args:
            memory_adapter: è¨˜æ†¶é«”ä»‹é¢å¡
            **kwargs: è¨ˆç®—åƒæ•¸
            
        Raises:
            ComputeExecutionError: è¨ˆç®—åŸ·è¡ŒéŒ¯èª¤
        """
        pass
        
    @abstractmethod  
    def apply_boundary_conditions(self, memory_adapter, **kwargs) -> None:
        """
        æ‡‰ç”¨é‚Šç•Œæ¢ä»¶
        
        Args:
            memory_adapter: è¨˜æ†¶é«”ä»‹é¢å¡
            **kwargs: é‚Šç•Œæ¢ä»¶åƒæ•¸
            
        Raises:
            ComputeExecutionError: é‚Šç•Œæ¢ä»¶æ‡‰ç”¨éŒ¯èª¤
        """
        pass
        
    @abstractmethod
    def compute_macroscopic_quantities(self, memory_adapter, **kwargs) -> None:
        """
        è¨ˆç®—å·¨è§€é‡ (å¯†åº¦ã€é€Ÿåº¦)
        
        Args:
            memory_adapter: è¨˜æ†¶é«”ä»‹é¢å¡
            **kwargs: è¨ˆç®—åƒæ•¸
            
        Raises:
            ComputeExecutionError: å·¨è§€é‡è¨ˆç®—éŒ¯èª¤
        """
        pass
        
    @abstractmethod
    def get_platform_info(self) -> Dict[str, Any]:
        """
        è¿”å›å¹³å°è©³ç´°ä¿¡æ¯
        
        Returns:
            Dict: å¹³å°é…ç½®èˆ‡èƒ½åŠ›ä¿¡æ¯
        """
        pass
        
    @abstractmethod
    def get_performance_metrics(self) -> Dict[str, Any]:
        """
        è¿”å›æ€§èƒ½æŒ‡æ¨™
        
        Returns:
            Dict: æ€§èƒ½çµ±è¨ˆæ•¸æ“š
        """
        pass
    
    def initialize_backend(self) -> None:
        """
        åˆå§‹åŒ–è¨ˆç®—å¾Œç«¯
        
        Raises:
            BackendInitializationError: åˆå§‹åŒ–å¤±æ•—
        """
        try:
            backend_logger.info(f"æ­£åœ¨åˆå§‹åŒ– {self.backend_type} å¾Œç«¯...")
            self._perform_initialization()
            self.is_initialized = True
            backend_logger.info(f"{self.backend_type} å¾Œç«¯åˆå§‹åŒ–æˆåŠŸ", self.backend_type)
            
        except Exception as e:
            error_msg = f"{self.backend_type} å¾Œç«¯åˆå§‹åŒ–å¤±æ•—: {e}"
            self._record_error(error_msg, "INIT_FAILED")
            raise BackendInitializationError(error_msg, self.backend_type, "INIT_FAILED")
    
    def cleanup_backend(self) -> None:
        """æ¸…ç†è¨ˆç®—å¾Œç«¯è³‡æº"""
        try:
            backend_logger.info(f"æ­£åœ¨æ¸…ç† {self.backend_type} å¾Œç«¯è³‡æº...")
            self._perform_cleanup()
            self.is_initialized = False
            backend_logger.info(f"{self.backend_type} å¾Œç«¯æ¸…ç†å®Œæˆ", self.backend_type)
            
        except Exception as e:
            backend_logger.error(f"{self.backend_type} å¾Œç«¯æ¸…ç†å¤±æ•—: {e}", self.backend_type)
    
    @contextmanager
    def safe_execution(self, operation_name: str):
        """
        å®‰å…¨åŸ·è¡Œä¸Šä¸‹æ–‡ç®¡ç†å™¨
        
        Args:
            operation_name: æ“ä½œåç¨±
            
        Yields:
            None
            
        Raises:
            ComputeExecutionError: åŸ·è¡ŒéŒ¯èª¤
        """
        start_time = time.time()
        
        try:
            backend_logger.info(f"é–‹å§‹åŸ·è¡Œ {operation_name}", self.backend_type)
            yield
            
        except Exception as e:
            error_msg = f"{operation_name} åŸ·è¡Œå¤±æ•—: {e}"
            self._record_error(error_msg, "EXECUTION_FAILED")
            backend_logger.error(error_msg, self.backend_type)
            raise ComputeExecutionError(error_msg, self.backend_type, "EXECUTION_FAILED")
            
        finally:
            execution_time = time.time() - start_time
            self.execution_times.append(execution_time)
            self.operation_count += 1
            
            # é™åˆ¶æ­·å²è¨˜éŒ„é•·åº¦
            if len(self.execution_times) > 1000:
                self.execution_times = self.execution_times[-500:]
    
    def _perform_initialization(self) -> None:
        """å­é¡å¯¦ç¾çš„å…·é«”åˆå§‹åŒ–é‚è¼¯"""
        pass
    
    def _perform_cleanup(self) -> None:
        """å­é¡å¯¦ç¾çš„å…·é«”æ¸…ç†é‚è¼¯"""
        pass
    
    def _record_error(self, error_msg: str, error_code: str) -> None:
        """è¨˜éŒ„éŒ¯èª¤ä¿¡æ¯"""
        error_record = {
            'timestamp': time.time(),
            'message': error_msg,
            'code': error_code,
            'backend_type': self.backend_type
        }
        self.error_history.append(error_record)
        self.last_error = error_record
        
        # é™åˆ¶éŒ¯èª¤æ­·å²é•·åº¦
        if len(self.error_history) > 100:
            self.error_history = self.error_history[-50:]
    
    def get_error_summary(self) -> Dict[str, Any]:
        """ç²å–éŒ¯èª¤æ‘˜è¦"""
        return {
            'total_errors': len(self.error_history),
            'last_error': self.last_error,
            'error_rate': len(self.error_history) / max(1, self.operation_count),
            'backend_type': self.backend_type
        }
    
    def get_basic_metrics(self) -> Dict[str, Any]:
        """ç²å–åŸºç¤æ€§èƒ½æŒ‡æ¨™"""
        if not self.execution_times:
            return {'status': 'no_data'}
            
        return {
            'backend_type': self.backend_type,
            'total_operations': self.operation_count,
            'avg_execution_time': np.mean(self.execution_times),
            'min_execution_time': np.min(self.execution_times),
            'max_execution_time': np.max(self.execution_times),
            'uptime_seconds': time.time() - self.creation_time,
            'is_initialized': self.is_initialized,
            'error_summary': self.get_error_summary()
        }


# ===== ä¼æ¥­ç´šå¾Œç«¯å·¥å» æ¨¡å¼ =====

class ComputeBackendFactory:
    """
    ä¼æ¥­ç´šè¨ˆç®—å¾Œç«¯å·¥å» é¡
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    - æ™ºèƒ½å¹³å°æª¢æ¸¬èˆ‡å¾Œç«¯é¸æ“‡
    - ä¼æ¥­ç´šéŒ¯èª¤è™•ç†èˆ‡é™ç´šæ©Ÿåˆ¶
    - å‹•æ…‹é…ç½®èˆ‡æ€§èƒ½æœ€ä½³åŒ–
    - å¾Œç«¯å¯¦ä¾‹ç”Ÿå‘½é€±æœŸç®¡ç†
    - è·¨å¹³å°ç›¸å®¹æ€§ä¿è­‰
    
    ç‰¹æ€§ï¼š
    - ç·šç¨‹å®‰å…¨çš„å–®ä¾‹æ¨¡å¼
    - æ•…éšœè½‰ç§»èˆ‡è‡ªå‹•é™ç´š
    - æ€§èƒ½åŸºæº–æ¸¬è©¦èˆ‡è©•ä¼°
    - æ™ºèƒ½å¿«å–èˆ‡é‡ç”¨æ©Ÿåˆ¶
    """
    
    _instance = None
    _lock = threading.Lock()
    
    def __new__(cls):
        """ç·šç¨‹å®‰å…¨çš„å–®ä¾‹æ¨¡å¼"""
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
                    cls._instance._initialized = False
        return cls._instance
    
    def __init__(self):
        """åˆå§‹åŒ–å·¥å» å¯¦ä¾‹"""
        if getattr(self, '_initialized', False):
            return
            
        self.backend_cache = {}
        self.platform_info = {}
        self.creation_history = []
        self.performance_benchmarks = {}
        self.fallback_chain = ['apple', 'cuda', 'cpu']
        self.lock = threading.Lock()
        self._initialized = True
        
        backend_logger.info("ğŸ—ï¸ è¨ˆç®—å¾Œç«¯å·¥å» åˆå§‹åŒ–å®Œæˆ")
    
    def create_optimal_backend(self, prefer_performance: bool = True) -> ComputeBackend:
        """
        å‰µå»ºæœ€ä½³è¨ˆç®—å¾Œç«¯
        
        Args:
            prefer_performance: å„ªå…ˆè€ƒæ…®æ€§èƒ½é‚„æ˜¯ç›¸å®¹æ€§
            
        Returns:
            ComputeBackend: æœ€ä½³å¾Œç«¯å¯¦ä¾‹
            
        Raises:
            BackendInitializationError: æ‰€æœ‰å¾Œç«¯éƒ½ä¸å¯ç”¨
        """
        with self.lock:
            backend_logger.info("ğŸ” é–‹å§‹æª¢æ¸¬æœ€ä½³è¨ˆç®—å¾Œç«¯...")
            
            # ç²å–å¹³å°ä¿¡æ¯
            optimal_platform = platform_detector.get_optimal_platform()
            backend_type = optimal_platform['backend_name']
            
            try:
                # å˜—è©¦å‰µå»ºæœ€ä½³å¾Œç«¯
                backend = self._create_backend_with_validation(backend_type)
                
                # è¨˜éŒ„æˆåŠŸå‰µå»º
                self._record_creation_success(backend_type, optimal_platform)
                backend_logger.info(f"âœ… æˆåŠŸå‰µå»º {optimal_platform['display_name']} å¾Œç«¯")
                
                return backend
                
            except Exception as e:
                backend_logger.warning(f"âš ï¸ æœ€ä½³å¾Œç«¯ {backend_type} å‰µå»ºå¤±æ•—: {e}")
                
                # å˜—è©¦æ•…éšœè½‰ç§»
                return self._attempt_fallback_creation(exclude=[backend_type])
    
    def create_backend(self, backend_type: str, 
                      validate: bool = True,
                      use_cache: bool = True) -> ComputeBackend:
        """
        æ ¹æ“šæŒ‡å®šé¡å‹å‰µå»ºå¾Œç«¯
        
        Args:
            backend_type: 'apple', 'cuda', 'cpu'
            validate: æ˜¯å¦é©—è­‰å¾Œç«¯å¯ç”¨æ€§
            use_cache: æ˜¯å¦ä½¿ç”¨å¿«å–å¯¦ä¾‹
            
        Returns:
            ComputeBackend: æŒ‡å®šé¡å‹çš„å¾Œç«¯å¯¦ä¾‹
            
        Raises:
            BackendInitializationError: å¾Œç«¯å‰µå»ºå¤±æ•—
        """
        with self.lock:
            # æª¢æŸ¥å¿«å–
            if use_cache and backend_type in self.backend_cache:
                cached_backend = self.backend_cache[backend_type]
                if self._validate_cached_backend(cached_backend):
                    backend_logger.info(f"â™»ï¸ ä½¿ç”¨å¿«å–çš„ {backend_type} å¾Œç«¯")
                    return cached_backend
                else:
                    # æ¸…ç†ç„¡æ•ˆå¿«å–
                    del self.backend_cache[backend_type]
            
            try:
                # å‰µå»ºæ–°å¾Œç«¯å¯¦ä¾‹
                backend = self._create_backend_with_validation(backend_type, validate)
                
                # å¿«å–æœ‰æ•ˆå¾Œç«¯
                if use_cache:
                    self.backend_cache[backend_type] = backend
                
                # è¨˜éŒ„å‰µå»ºæ­·å²
                self._record_creation_success(backend_type)
                
                return backend
                
            except Exception as e:
                error_msg = f"å‰µå»º {backend_type} å¾Œç«¯å¤±æ•—: {e}"
                backend_logger.error(error_msg)
                raise BackendInitializationError(error_msg, backend_type, "CREATION_FAILED")
    
    def get_available_backends(self) -> List[Dict[str, Any]]:
        """
        ç²å–æ‰€æœ‰å¯ç”¨çš„å¾Œç«¯ä¿¡æ¯
        
        Returns:
            List[Dict]: å¯ç”¨å¾Œç«¯åˆ—è¡¨
        """
        available_backends = []
        all_platforms = platform_detector.detect_all_platforms()
        
        for platform_info in all_platforms:
            backend_type = platform_info['backend_name']
            
            try:
                # é©—è­‰å¾Œç«¯å¯ç”¨æ€§
                if platform_detector.validate_platform_availability(backend_type):
                    available_backends.append({
                        **platform_info,
                        'is_available': True,
                        'validation_status': 'passed'
                    })
                else:
                    available_backends.append({
                        **platform_info,
                        'is_available': False,
                        'validation_status': 'failed'
                    })
                    
            except Exception as e:
                available_backends.append({
                    **platform_info,
                    'is_available': False,
                    'validation_status': 'error',
                    'error_message': str(e)
                })
        
        return available_backends
    
    def benchmark_all_backends(self, iterations: int = 10) -> Dict[str, Dict[str, Any]]:
        """
        å°æ‰€æœ‰å¯ç”¨å¾Œç«¯é€²è¡Œæ€§èƒ½åŸºæº–æ¸¬è©¦
        
        Args:
            iterations: æ¸¬è©¦è¿­ä»£æ¬¡æ•¸
            
        Returns:
            Dict: å„å¾Œç«¯æ€§èƒ½åŸºæº–çµæœ
        """
        benchmarks = {}
        available_backends = self.get_available_backends()
        
        for backend_info in available_backends:
            if not backend_info['is_available']:
                continue
                
            backend_type = backend_info['backend_name']
            backend_logger.info(f"ğŸƒâ€â™‚ï¸ é–‹å§‹åŸºæº–æ¸¬è©¦ {backend_type} å¾Œç«¯...")
            
            try:
                backend = self.create_backend(backend_type, use_cache=False)
                benchmark_result = self._run_performance_benchmark(backend, iterations)
                benchmarks[backend_type] = benchmark_result
                
                backend_logger.info(f"âœ… {backend_type} åŸºæº–æ¸¬è©¦å®Œæˆ")
                
            except Exception as e:
                benchmarks[backend_type] = {
                    'status': 'failed',
                    'error': str(e)
                }
                backend_logger.error(f"âŒ {backend_type} åŸºæº–æ¸¬è©¦å¤±æ•—: {e}")
        
        # å¿«å–åŸºæº–æ¸¬è©¦çµæœ
        self.performance_benchmarks = benchmarks
        return benchmarks
    
    def _create_backend_with_validation(self, backend_type: str, 
                                       validate: bool = True) -> ComputeBackend:
        """å‰µå»ºä¸¦é©—è­‰å¾Œç«¯å¯¦ä¾‹"""
        # é©—è­‰å¹³å°å¯ç”¨æ€§
        if validate and not platform_detector.validate_platform_availability(backend_type):
            raise BackendInitializationError(
                f"{backend_type} å¹³å°ä¸å¯ç”¨æˆ–æœªæ­£ç¢ºé…ç½®",
                backend_type, "PLATFORM_UNAVAILABLE"
            )
        
        # å‹•æ…‹å°å…¥ä¸¦å‰µå»ºå¾Œç«¯
        if backend_type == 'apple':
            try:
                from .apple_backend import AppleBackend
                backend = AppleBackend()
            except ImportError as e:
                raise BackendInitializationError(
                    f"Apple å¾Œç«¯å°å…¥å¤±æ•—: {e}", backend_type, "IMPORT_FAILED")
                
        elif backend_type == 'cuda':
            try:
                from .cuda_backend import CUDABackend
                backend = CUDABackend()
            except ImportError as e:
                raise BackendInitializationError(
                    f"CUDA å¾Œç«¯å°å…¥å¤±æ•—: {e}", backend_type, "IMPORT_FAILED")
                
        elif backend_type == 'cpu':
            try:
                from .cpu_backend import CPUBackend
                backend = CPUBackend()
            except ImportError as e:
                raise BackendInitializationError(
                    f"CPU å¾Œç«¯å°å…¥å¤±æ•—: {e}", backend_type, "IMPORT_FAILED")
        else:
            raise BackendInitializationError(
                f"æœªçŸ¥çš„å¾Œç«¯é¡å‹: {backend_type}", backend_type, "UNKNOWN_BACKEND")
        
        # åˆå§‹åŒ–å¾Œç«¯
        if validate:
            backend.initialize_backend()
        
        return backend
    
    def _attempt_fallback_creation(self, exclude: List[str] = None) -> ComputeBackend:
        """å˜—è©¦æ•…éšœè½‰ç§»å‰µå»º"""
        exclude = exclude or []
        
        for backend_type in self.fallback_chain:
            if backend_type in exclude:
                continue
                
            try:
                backend_logger.info(f"ğŸ”„ å˜—è©¦æ•…éšœè½‰ç§»åˆ° {backend_type} å¾Œç«¯...")
                backend = self._create_backend_with_validation(backend_type)
                backend_logger.info(f"âœ… æ•…éšœè½‰ç§»æˆåŠŸï¼Œä½¿ç”¨ {backend_type} å¾Œç«¯")
                return backend
                
            except Exception as e:
                backend_logger.warning(f"âš ï¸ æ•…éšœè½‰ç§»åˆ° {backend_type} å¤±æ•—: {e}")
                continue
        
        # æ‰€æœ‰å¾Œç«¯éƒ½ä¸å¯ç”¨
        raise BackendInitializationError(
            "æ‰€æœ‰è¨ˆç®—å¾Œç«¯éƒ½ä¸å¯ç”¨ï¼Œç„¡æ³•å‰µå»ºå¾Œç«¯å¯¦ä¾‹",
            "all", "ALL_BACKENDS_FAILED"
        )
    
    def _validate_cached_backend(self, backend: ComputeBackend) -> bool:
        """é©—è­‰å¿«å–å¾Œç«¯çš„æœ‰æ•ˆæ€§"""
        try:
            return (backend is not None and 
                   hasattr(backend, 'is_initialized') and
                   backend.is_initialized)
        except Exception:
            return False
    
    def _record_creation_success(self, backend_type: str, 
                                platform_info: Dict[str, Any] = None):
        """è¨˜éŒ„å¾Œç«¯å‰µå»ºæˆåŠŸ"""
        record = {
            'timestamp': time.time(),
            'backend_type': backend_type,
            'status': 'success',
            'platform_info': platform_info
        }
        self.creation_history.append(record)
        
        # é™åˆ¶æ­·å²è¨˜éŒ„é•·åº¦
        if len(self.creation_history) > 100:
            self.creation_history = self.creation_history[-50:]
    
    def _run_performance_benchmark(self, backend: ComputeBackend, 
                                  iterations: int) -> Dict[str, Any]:
        """é‹è¡Œæ€§èƒ½åŸºæº–æ¸¬è©¦"""
        start_time = time.time()
        execution_times = []
        
        for i in range(iterations):
            iter_start = time.time()
            
            # é€™è£¡æ‡‰è©²é‹è¡Œå¯¦éš›çš„è¨ˆç®—æ¸¬è©¦
            # æš«æ™‚ä½¿ç”¨ç°¡å–®çš„æ™‚é–“æ¸¬é‡
            try:
                # æ¨¡æ“¬è¨ˆç®—æ“ä½œ
                time.sleep(0.001)  # 1ms æ¨¡æ“¬è¨ˆç®—
                execution_times.append(time.time() - iter_start)
            except Exception as e:
                backend_logger.warning(f"åŸºæº–æ¸¬è©¦è¿­ä»£ {i} å¤±æ•—: {e}")
        
        total_time = time.time() - start_time
        
        if not execution_times:
            return {'status': 'failed', 'error': 'æ‰€æœ‰è¿­ä»£éƒ½å¤±æ•—'}
        
        return {
            'status': 'success',
            'iterations': len(execution_times),
            'total_time': total_time,
            'avg_execution_time': np.mean(execution_times),
            'min_execution_time': np.min(execution_times),
            'max_execution_time': np.max(execution_times),
            'std_execution_time': np.std(execution_times),
            'throughput': len(execution_times) / total_time,
            'backend_type': backend.backend_type
        }
    
    def get_factory_statistics(self) -> Dict[str, Any]:
        """ç²å–å·¥å» çµ±è¨ˆä¿¡æ¯"""
        return {
            'total_backends_created': len(self.creation_history),
            'cached_backends': list(self.backend_cache.keys()),
            'creation_history': self.creation_history[-10:],  # æœ€è¿‘10æ¬¡å‰µå»º
            'performance_benchmarks': self.performance_benchmarks,
            'available_platforms': len(platform_detector.detected_platforms),
            'fallback_chain': self.fallback_chain
        }
    
    def cleanup_all_backends(self):
        """æ¸…ç†æ‰€æœ‰å¾Œç«¯è³‡æº"""
        with self.lock:
            backend_logger.info("ğŸ§¹ é–‹å§‹æ¸…ç†æ‰€æœ‰å¾Œç«¯è³‡æº...")
            
            for backend_type, backend in self.backend_cache.items():
                try:
                    backend.cleanup_backend()
                    backend_logger.info(f"âœ… {backend_type} å¾Œç«¯æ¸…ç†å®Œæˆ")
                except Exception as e:
                    backend_logger.error(f"âŒ {backend_type} å¾Œç«¯æ¸…ç†å¤±æ•—: {e}")
            
            self.backend_cache.clear()
            backend_logger.info("ğŸ§¹ æ‰€æœ‰å¾Œç«¯è³‡æºæ¸…ç†å®Œæˆ")
    
    def __del__(self):
        """ææ§‹å‡½æ•¸ï¼Œç¢ºä¿è³‡æºæ¸…ç†"""
        try:
            self.cleanup_all_backends()
        except Exception:
            pass


# ===== ä¾¿åˆ©å‡½æ•¸èˆ‡å…¨åŸŸå¯¦ä¾‹ =====

# å…¨åŸŸå·¥å» å¯¦ä¾‹
backend_factory = ComputeBackendFactory()


def create_optimal_backend(**kwargs) -> ComputeBackend:
    """
    ä¾¿åˆ©å‡½æ•¸ï¼šå‰µå»ºæœ€ä½³å¾Œç«¯
    
    Returns:
        ComputeBackend: æœ€ä½³å¾Œç«¯å¯¦ä¾‹
    """
    return backend_factory.create_optimal_backend(**kwargs)


def create_backend(backend_type: str, **kwargs) -> ComputeBackend:
    """
    ä¾¿åˆ©å‡½æ•¸ï¼šå‰µå»ºæŒ‡å®šé¡å‹å¾Œç«¯
    
    Args:
        backend_type: å¾Œç«¯é¡å‹
        **kwargs: å…¶ä»–åƒæ•¸
        
    Returns:
        ComputeBackend: å¾Œç«¯å¯¦ä¾‹
    """
    return backend_factory.create_backend(backend_type, **kwargs)


def get_available_backends() -> List[Dict[str, Any]]:
    """
    ä¾¿åˆ©å‡½æ•¸ï¼šç²å–å¯ç”¨å¾Œç«¯åˆ—è¡¨
    
    Returns:
        List[Dict]: å¯ç”¨å¾Œç«¯ä¿¡æ¯
    """
    return backend_factory.get_available_backends()


def cleanup_backends():
    """ä¾¿åˆ©å‡½æ•¸ï¼šæ¸…ç†æ‰€æœ‰å¾Œç«¯è³‡æº"""
    backend_factory.cleanup_all_backends()


# ===== æ¨¡çµ„å°å‡º =====

__all__ = [
    # åŸºç¤é¡åˆ¥
    'ComputeBackend',
    'ComputeBackendFactory',
    'PlatformDetector',
    'BackendLogger',
    
    # éŒ¯èª¤é¡åˆ¥
    'BackendError',
    'PlatformDetectionError', 
    'BackendInitializationError',
    'ComputeExecutionError',
    'MemoryAllocationError',
    'PerformanceDegradationError',
    
    # æšèˆ‰é¡åˆ¥
    'PlatformType',
    'BackendPriority',
    
    # å…¨åŸŸå¯¦ä¾‹
    'backend_factory',
    'platform_detector',
    'backend_logger',
    
    # ä¾¿åˆ©å‡½æ•¸
    'create_optimal_backend',
    'create_backend',
    'get_available_backends',
    'cleanup_backends'
]