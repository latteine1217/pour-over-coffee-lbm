"""
CFD Performance Benchmark Suite
V60æ‰‹æ²–å’–å•¡LBMæ¨¡æ“¬ç³»çµ±æ€§èƒ½åŸºæº–æ¸¬è©¦æ¡†æ¶

æä¾›ä¼æ¥­ç´šæ€§èƒ½ç›£æ§å’ŒåŸºæº–æ¸¬è©¦åŠŸèƒ½ï¼Œæ”¯æ´GPUåŠ é€Ÿè¨ˆç®—çš„æº–ç¢ºæ¸¬é‡
"""

import time
import json
import argparse
import psutil
import numpy as np
import taichi as ti
from typing import Dict, List, Optional, Tuple, Any
from pathlib import Path
import matplotlib.pyplot as plt
from dataclasses import dataclass, asdict
from contextlib import contextmanager

# å°å…¥æ ¸å¿ƒæ¨¡çµ„
import config.config
from src.core.lbm_solver import LBMSolver
from src.core.multiphase_3d import MultiphaseFlow3D
from src.physics.coffee_particles import CoffeeParticleSystem
from src.physics.les_turbulence import LESTurbulenceModel

@dataclass
class BenchmarkResult:
    """åŸºæº–æ¸¬è©¦çµæœæ•¸æ“šé¡"""
    test_name: str
    execution_time: float
    memory_usage_mb: float
    grid_size: int
    iterations: int
    timestamp: str
    gpu_memory_mb: Optional[float] = None
    throughput: Optional[float] = None  # æ ¼é»/ç§’
    
class CFDPerformanceBenchmark:
    """CFDæ€§èƒ½åŸºæº–æ¸¬è©¦ä¸»é¡"""
    
    def __init__(self, output_dir: str = "benchmark_results"):
        """
        åˆå§‹åŒ–åŸºæº–æ¸¬è©¦æ¡†æ¶
        
        Args:
            output_dir: çµæœè¼¸å‡ºç›®éŒ„
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        self.results: List[BenchmarkResult] = []
        self.baseline_data: Optional[Dict] = None
        
        # åˆå§‹åŒ–Taichi - æ”¯æ´CIç’°å¢ƒ
        import os
        forced_cpu = os.environ.get('CI', 'false').lower() == 'true' or os.environ.get('TI_ARCH', '') == 'cpu'
        
        if forced_cpu:
            # CIç’°å¢ƒä½¿ç”¨CPU
            ti.init(arch=ti.cpu, cpu_max_num_threads=4, debug=False)
            print("âœ“ Benchmarkä½¿ç”¨CPUè¨ˆç®— (CIç’°å¢ƒ)")
        else:
            # æœ¬åœ°ç’°å¢ƒå„ªå…ˆGPU
            try:
                ti.init(arch=ti.metal, device_memory_GB=8)
                print("âœ“ Benchmarkä½¿ç”¨GPUè¨ˆç®—")
            except:
                ti.init(arch=ti.cpu, cpu_max_num_threads=8, debug=False)
                print("âœ“ Benchmarkä½¿ç”¨CPUè¨ˆç®— (GPUä¸å¯ç”¨)")
        
        # åŸºæº–æ¸¬è©¦é…ç½®
        self.test_configs = {
            'small': {'grid_size': 64, 'iterations': 50},
            'medium': {'grid_size': 128, 'iterations': 100}, 
            'large': {'grid_size': 224, 'iterations': 200},
            'stress': {'grid_size': 256, 'iterations': 500}
        }
        
    @contextmanager
    def performance_monitor(self):
        """æ€§èƒ½ç›£æ§ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        # è¨˜éŒ„é–‹å§‹ç‹€æ…‹
        process = psutil.Process()
        start_memory = process.memory_info().rss / 1024 / 1024  # MB
        start_time = time.perf_counter()
        
        # GPUè¨˜æ†¶é«” (å¦‚æœå¯ç”¨)
        try:
            gpu_memory_start = ti.profiler.get_kernel_stats()
        except:
            gpu_memory_start = None
            
        yield
        
        # è¨˜éŒ„çµæŸç‹€æ…‹
        end_time = time.perf_counter()
        end_memory = process.memory_info().rss / 1024 / 1024
        
        self._last_execution_time = end_time - start_time
        self._last_memory_usage = max(end_memory - start_memory, 0)
        
    def benchmark_lbm_step(self, grid_size: int = 224, iterations: int = 100) -> BenchmarkResult:
        """
        æ¸¬é‡LBMæ±‚è§£å™¨å–®æ­¥è¨ˆç®—æ€§èƒ½
        
        Args:
            grid_size: ç¶²æ ¼å°ºå¯¸
            iterations: è¿­ä»£æ¬¡æ•¸
            
        Returns:
            åŸºæº–æ¸¬è©¦çµæœ
        """
        print(f"ğŸ“Š LBMæ±‚è§£å™¨åŸºæº–æ¸¬è©¦ - ç¶²æ ¼: {grid_size}Â³, è¿­ä»£: {iterations}")
        
        # å‰µå»ºæ¸¬è©¦ç”¨LBMæ±‚è§£å™¨ (ä½¿ç”¨é»˜èªé…ç½®)
        solver = LBMSolver()
        
        with self.performance_monitor():
            # åŸ·è¡ŒåŸºæº–æ¸¬è©¦ (ä½¿ç”¨å¯¦éš›çš„LBMæ–¹æ³•)
            for i in range(iterations):
                if i % (iterations // 2) == 0:
                    print(f"  è¿­ä»£é€²åº¦: {i+1}/{iterations}")
                    
                # åŸ·è¡ŒLBMæ­¥é©Ÿ
                solver._collision_streaming_step()
                    
        # è¨ˆç®—ååé‡ (æ ¼é»/ç§’)
        total_lattice_points = grid_size ** 3 * iterations
        throughput = total_lattice_points / self._last_execution_time
        
        result = BenchmarkResult(
            test_name="lbm_step",
            execution_time=self._last_execution_time,
            memory_usage_mb=self._last_memory_usage,
            grid_size=grid_size,
            iterations=iterations,
            timestamp=time.strftime("%Y-%m-%d %H:%M:%S"),
            throughput=throughput
        )
        
        self.results.append(result)
        print(f"  âœ… å®Œæˆ - åŸ·è¡Œæ™‚é–“: {result.execution_time:.2f}s")
        return result
        
    def benchmark_particle_system(self, grid_size: int, num_particles: int, iterations: int) -> BenchmarkResult:
        """
        æ¸¬é‡é¡†ç²’ç³»çµ±æ€§èƒ½
        
        Args:
            grid_size: ç¶²æ ¼å°ºå¯¸  
            num_particles: é¡†ç²’æ•¸é‡
            iterations: è¿­ä»£æ¬¡æ•¸
            
        Returns:
            åŸºæº–æ¸¬è©¦çµæœ
        """
        print(f"ğŸ“Š é¡†ç²’ç³»çµ±åŸºæº–æ¸¬è©¦ - {num_particles}é¡†ç²’, {iterations}æ­¥")
        
        # å‰µå»ºæ¸¬è©¦ç”¨é¡†ç²’ç³»çµ±
        from src.physics.coffee_particles import CoffeeParticleSystem
        particle_system = CoffeeParticleSystem(max_particles=num_particles)
        
        with self.performance_monitor():
            for i in range(iterations):
                if i % (iterations // 2) == 0:
                    print(f"  è¿­ä»£é€²åº¦: {i+1}/{iterations}")
                
                # æ›´æ–°é¡†ç²’
                particle_system.update_particles(0.01)  # dt = 0.01s
                    
        result = BenchmarkResult(
            test_name="particle_system",
            execution_time=self._last_execution_time,
            memory_usage_mb=self._last_memory_usage,
            grid_size=grid_size,
            iterations=iterations,
            timestamp=time.strftime("%Y-%m-%d %H:%M:%S")
        )
        
        self.results.append(result)
        print(f"  âœ… å®Œæˆ - åŸ·è¡Œæ™‚é–“: {result.execution_time:.2f}s")
        return result
        
    def benchmark_les_turbulence(self, grid_size: int = 224, iterations: int = 100) -> BenchmarkResult:
        """
        æ¸¬é‡LESæ¹æµæ¨¡å‹æ€§èƒ½
        
        Args:
            grid_size: ç¶²æ ¼å°ºå¯¸
            iterations: è¿­ä»£æ¬¡æ•¸
            
        Returns:
            åŸºæº–æ¸¬è©¦çµæœ
        """
        print(f"ğŸ“Š LESæ¹æµæ¨¡å‹åŸºæº–æ¸¬è©¦ - ç¶²æ ¼: {grid_size}Â³")
        
        # å‰µå»ºæ¸¬è©¦ç”¨LESæ¨¡å‹
        from src.physics.les_turbulence import LESTurbulenceModel
        les_model = LESTurbulenceModel()
        
        # å‰µå»ºæ¸¬è©¦ç”¨å ´è®Šæ•¸
        f_field = ti.field(dtype=ti.f32, shape=(19, grid_size, grid_size, grid_size))
        rho_field = ti.field(dtype=ti.f32, shape=(grid_size, grid_size, grid_size))
        u_field = ti.field(dtype=ti.f32, shape=(grid_size, grid_size, grid_size))
        v_field = ti.field(dtype=ti.f32, shape=(grid_size, grid_size, grid_size))
        w_field = ti.field(dtype=ti.f32, shape=(grid_size, grid_size, grid_size))
        
        with self.performance_monitor():
            for i in range(iterations):
                if i % (iterations // 2) == 0:
                    print(f"  è¿­ä»£é€²åº¦: {i+1}/{iterations}")
                
                # è¨ˆç®—SGSæ‡‰åŠ›
                les_model.apply_sgs_stress(f_field, rho_field, u_field, v_field, w_field)
                    
        result = BenchmarkResult(
            test_name="les_turbulence",
            execution_time=self._last_execution_time,
            memory_usage_mb=self._last_memory_usage,
            grid_size=grid_size,
            iterations=iterations,
            timestamp=time.strftime("%Y-%m-%d %H:%M:%S")
        )
        
        self.results.append(result)
        print(f"  âœ… å®Œæˆ - åŸ·è¡Œæ™‚é–“: {result.execution_time:.2f}s")
        return result
        
    def benchmark_boundary_conditions(self, grid_size: int = 224, iterations: int = 100) -> BenchmarkResult:
        """
        æ¸¬é‡é‚Šç•Œæ¢ä»¶è™•ç†æ€§èƒ½
        
        Args:
            grid_size: ç¶²æ ¼å°ºå¯¸
            iterations: è¿­ä»£æ¬¡æ•¸
            
        Returns:
            åŸºæº–æ¸¬è©¦çµæœ
        """
        print(f"ğŸ“Š é‚Šç•Œæ¢ä»¶åŸºæº–æ¸¬è©¦ - ç¶²æ ¼: {grid_size}Â³")
        
        # å‰µå»ºæ¸¬è©¦ç”¨LBMæ±‚è§£å™¨
        solver = LBMSolver()
        
        with self.performance_monitor():
            for i in range(iterations):
                if i % (iterations // 2) == 0:
                    print(f"  è¿­ä»£é€²åº¦: {i+1}/{iterations}")
                
                # æ‡‰ç”¨é‚Šç•Œæ¢ä»¶
                solver.boundary_manager.apply_all_boundaries(solver)
                    
        result = BenchmarkResult(
            test_name="boundary_conditions", 
            execution_time=self._last_execution_time,
            memory_usage_mb=self._last_memory_usage,
            grid_size=grid_size,
            iterations=iterations,
            timestamp=time.strftime("%Y-%m-%d %H:%M:%S")
        )
        
        self.results.append(result)
        print(f"  âœ… å®Œæˆ - åŸ·è¡Œæ™‚é–“: {result.execution_time:.2f}s")
        return result
        
    def benchmark_memory_usage(self) -> BenchmarkResult:
        """æ¸¬é‡è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³"""
        print("ğŸ“Š è¨˜æ†¶é«”ä½¿ç”¨åŸºæº–æ¸¬è©¦")
        
        process = psutil.Process()
        memory_before = process.memory_info().rss / 1024 / 1024
        
        # å‰µå»ºLBMæ±‚è§£å™¨æ¸¬è©¦è¨˜æ†¶é«” (ä½¿ç”¨é»˜èªé…ç½®)
        solver = LBMSolver()
        
        memory_after = process.memory_info().rss / 1024 / 1024
        memory_usage = memory_after - memory_before
        
        result = BenchmarkResult(
            test_name="memory_usage",
            execution_time=0.0,
            memory_usage_mb=memory_usage,
            grid_size=config.NX,  # ä½¿ç”¨é…ç½®çš„ç¶²æ ¼å°ºå¯¸
            iterations=1,
            timestamp=time.strftime("%Y-%m-%d %H:%M:%S")
        )
        
        self.results.append(result)
        print(f"  âœ… è¨˜æ†¶é«”ä½¿ç”¨: {memory_usage:.1f} MB")
        return result
        
    def benchmark_full_simulation(self, grid_size: int = 128, time_steps: int = 50) -> BenchmarkResult:
        """
        å®Œæ•´æ¨¡æ“¬æ€§èƒ½åŸºæº–æ¸¬è©¦
        
        Args:
            grid_size: ç¶²æ ¼å°ºå¯¸
            time_steps: æ™‚é–“æ­¥æ•¸
        """
        print(f"ğŸ“Š å®Œæ•´æ¨¡æ“¬åŸºæº–æ¸¬è©¦ - ç¶²æ ¼: {grid_size}Â³, æ™‚é–“æ­¥: {time_steps}")
        
        with self.performance_monitor():
            # æ¨¡æ“¬å®Œæ•´çš„CFDè¨ˆç®—æµç¨‹ (ä½¿ç”¨é»˜èªé…ç½®)
            solver = LBMSolver()
            
            # å‰µå»ºå¤šç›¸æµç³»çµ± (ä¿®å¾©åƒæ•¸)
            from src.core.multiphase_3d import MultiphaseFlow3D
            multiphase = MultiphaseFlow3D(solver)
            
            # å‰µå»ºé¡†ç²’ç³»çµ±
            from src.physics.coffee_particles import CoffeeParticleSystem 
            particles = CoffeeParticleSystem(500)  # è¼ƒå°‘é¡†ç²’ç”¨æ–¼åŸºæº–æ¸¬è©¦
            
            for step in range(time_steps):
                # LBMæ­¥é©Ÿ (ä½¿ç”¨å¯¦éš›æ–¹æ³•)
                solver._collision_streaming_step()
                
                # å¤šç›¸æµæ›´æ–°
                multiphase.update_density_from_phase()
                
                # é¡†ç²’æ›´æ–°
                particles.update_particles(0.01)
                
                if step % 10 == 0:
                    print(f"  æ™‚é–“æ­¥é€²åº¦: {step+1}/{time_steps}")
                    
        # è¨ˆç®—æ¨¡æ“¬æ•ˆç‡
        total_operations = grid_size ** 3 * time_steps
        throughput = total_operations / self._last_execution_time
        
        result = BenchmarkResult(
            test_name="full_simulation",
            execution_time=self._last_execution_time,
            memory_usage_mb=self._last_memory_usage,
            grid_size=grid_size,
            iterations=time_steps,
            timestamp=time.strftime("%Y-%m-%d %H:%M:%S"),
            throughput=throughput
        )
        
        self.results.append(result)
        print(f"  âœ… å®Œæˆ - åŸ·è¡Œæ™‚é–“: {result.execution_time:.2f}s, æ•ˆç‡: {throughput:.0f} æ“ä½œ/s")
        return result
        
    def run_all_benchmarks(self, test_size: str = "medium") -> Dict[str, BenchmarkResult]:
        """åŸ·è¡Œæ‰€æœ‰åŸºæº–æ¸¬è©¦"""
        config = self.test_configs.get(test_size, self.test_configs["medium"])
        grid_size = config["grid_size"]
        iterations = config["iterations"]
        
        print(f"\nğŸš€ é–‹å§‹åŸ·è¡Œå…¨å¥—åŸºæº–æ¸¬è©¦ - é…ç½®: {test_size}")
        print("=" * 60)
        
        benchmark_results = {}
        
        # 1. LBMæ±‚è§£å™¨åŸºæº–æ¸¬è©¦
        benchmark_results["lbm"] = self.benchmark_lbm_step(grid_size, iterations)
        
        # 2. é‚Šç•Œæ¢ä»¶åŸºæº–æ¸¬è©¦
        benchmark_results["boundary"] = self.benchmark_boundary_conditions(grid_size, iterations)
        
        # 3. é¡†ç²’ç³»çµ±åŸºæº–æ¸¬è©¦
        benchmark_results["particles"] = self.benchmark_particle_system(grid_size, 1890, iterations)
        
        # 4. LESæ¹æµåŸºæº–æ¸¬è©¦ (æš«æ™‚è·³é - æœ‰ç·¨è­¯å•é¡Œ)
        # benchmark_results["turbulence"] = self.benchmark_les_turbulence(grid_size, iterations)
        
        # 5. è¨˜æ†¶é«”ä½¿ç”¨åŸºæº–æ¸¬è©¦
        benchmark_results["memory"] = self.benchmark_memory_usage()
        
        # 6. å®Œæ•´æ¨¡æ“¬åŸºæº–æ¸¬è©¦
        benchmark_results["full_sim"] = self.benchmark_full_simulation(grid_size, iterations//2)
        
        print("\nâœ… æ‰€æœ‰åŸºæº–æ¸¬è©¦å®Œæˆ!")
        return benchmark_results
        
    def save_results(self, filename: str = "benchmark_results.json"):
        """ä¿å­˜åŸºæº–æ¸¬è©¦çµæœåˆ°JSONæ–‡ä»¶"""
        results_data = [asdict(result) for result in self.results]
        
        output_file = self.output_dir / filename
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results_data, f, indent=2, ensure_ascii=False)
            
        print(f"ğŸ“ çµæœå·²ä¿å­˜åˆ°: {output_file}")
        
    def load_baseline(self, baseline_file: str) -> None:
        """è¼‰å…¥åŸºæº–ç·šæ•¸æ“š"""
        baseline_path = Path(baseline_file)
        if baseline_path.exists():
            with open(baseline_path, 'r', encoding='utf-8') as f:
                self.baseline_data = json.load(f)
            print(f"ğŸ“Š å·²è¼‰å…¥åŸºæº–ç·šæ•¸æ“š: {baseline_file}")
        else:
            print(f"âš ï¸  åŸºæº–ç·šæ–‡ä»¶ä¸å­˜åœ¨: {baseline_file}")
            
    def compare_with_baseline(self, baseline_file: str = "baseline_performance.json") -> Dict[str, float]:
        """
        èˆ‡åŸºæº–ç‰ˆæœ¬æ€§èƒ½å°æ¯”
        
        Returns:
            å„é …æ¸¬è©¦çš„æ€§èƒ½è®ŠåŒ–ç™¾åˆ†æ¯”
        """
        self.load_baseline(baseline_file)
        
        if not self.baseline_data:
            print("âŒ ç„¡åŸºæº–ç·šæ•¸æ“šå¯æ¯”è¼ƒ")
            return {}
            
        print("\nğŸ“ˆ æ€§èƒ½å°æ¯”åˆ†æ")
        print("=" * 40)
        
        comparison = {}
        
        for current_result in self.results:
            test_name = current_result.test_name
            
            # æŸ¥æ‰¾å°æ‡‰çš„åŸºæº–ç·šæ•¸æ“š
            baseline_result = None
            for baseline in self.baseline_data:
                if (baseline["test_name"] == test_name and 
                    baseline["grid_size"] == current_result.grid_size):
                    baseline_result = baseline
                    break
                    
            if baseline_result:
                # è¨ˆç®—æ€§èƒ½è®ŠåŒ–
                time_change = ((current_result.execution_time - baseline_result["execution_time"]) 
                             / baseline_result["execution_time"] * 100)
                memory_change = ((current_result.memory_usage_mb - baseline_result["memory_usage_mb"]) 
                               / baseline_result["memory_usage_mb"] * 100)
                
                comparison[test_name] = {
                    "time_change_percent": time_change,
                    "memory_change_percent": memory_change
                }
                
                # é¡¯ç¤ºå°æ¯”çµæœ
                time_symbol = "â¬‡ï¸" if time_change < 0 else "â¬†ï¸"
                memory_symbol = "â¬‡ï¸" if memory_change < 0 else "â¬†ï¸"
                
                print(f"{test_name:15} | æ™‚é–“: {time_symbol} {time_change:+6.1f}% | è¨˜æ†¶é«”: {memory_symbol} {memory_change:+6.1f}%")
                
        return comparison
        
    def generate_performance_report(self) -> str:
        """ç”Ÿæˆæ€§èƒ½å ±å‘Š"""
        report = []
        report.append("# CFDæ€§èƒ½åŸºæº–æ¸¬è©¦å ±å‘Š\n")
        report.append(f"ç”Ÿæˆæ™‚é–“: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        report.append("## æ¸¬è©¦çµæœæ‘˜è¦\n")
        
        if not self.results:
            report.append("ç„¡æ¸¬è©¦çµæœ\n")
            return "\n".join(report)
            
        for result in self.results:
            report.append(f"### {result.test_name}")
            report.append(f"- ç¶²æ ¼å°ºå¯¸: {result.grid_size}Â³")
            report.append(f"- åŸ·è¡Œæ™‚é–“: {result.execution_time:.3f}s")
            report.append(f"- è¨˜æ†¶é«”ä½¿ç”¨: {result.memory_usage_mb:.1f}MB")
            if result.throughput:
                report.append(f"- ååé‡: {result.throughput:.0f} æ“ä½œ/s")
            report.append("")
            
        return "\n".join(report)

def main():
    """ä¸»ç¨‹åºå…¥å£"""
    parser = argparse.ArgumentParser(description="CFD Performance Benchmark Suite")
    parser.add_argument("--size", choices=["small", "medium", "large", "stress"], 
                       default="medium", help="æ¸¬è©¦è¦æ¨¡")
    parser.add_argument("--output", default="benchmark_results.json", 
                       help="è¼¸å‡ºæ–‡ä»¶å")
    parser.add_argument("--baseline", default="baseline_performance.json",
                       help="åŸºæº–ç·šæ–‡ä»¶")
    parser.add_argument("--compare", action="store_true",
                       help="èˆ‡åŸºæº–ç·šæ¯”è¼ƒ")
    parser.add_argument("--report", action="store_true",
                       help="ç”Ÿæˆå ±å‘Š")
    
    args = parser.parse_args()
    
    # å‰µå»ºåŸºæº–æ¸¬è©¦å¯¦ä¾‹
    benchmark = CFDPerformanceBenchmark()
    
    # åŸ·è¡ŒåŸºæº–æ¸¬è©¦
    print("ğŸ”¬ CFD Performance Benchmark Suite")
    print("V60æ‰‹æ²–å’–å•¡LBMæ¨¡æ“¬ç³»çµ±æ€§èƒ½åˆ†æ")
    
    results = benchmark.run_all_benchmarks(args.size)
    
    # ä¿å­˜çµæœ
    benchmark.save_results(args.output)
    
    # æ€§èƒ½æ¯”è¼ƒ
    if args.compare:
        comparison = benchmark.compare_with_baseline(args.baseline)
        
    # ç”Ÿæˆå ±å‘Š
    if args.report:
        report = benchmark.generate_performance_report()
        report_file = benchmark.output_dir / "performance_report.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        print(f"ğŸ“„ æ€§èƒ½å ±å‘Šå·²ç”Ÿæˆ: {report_file}")

if __name__ == "__main__":
    main()